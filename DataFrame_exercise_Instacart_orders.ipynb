{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instacart Orders\n",
    "The dataset is a relational set of files describing customers' orders over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import isnan, when, count, col, countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = 'dataFrame'\n",
    "spark = SparkSession.builder.appName(app_name).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into Spark DataFrame\n",
    "Two files, order_products_prior.csv and orders.csv, are not loaded to GitHub because the file size is over 100 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aisles_path = '..\\pyspark-training\\data\\df-exercise-1\\aisles.csv'\n",
    "departments_path = '..\\pyspark-training\\data\\df-exercise-1\\departments.csv'\n",
    "order_products_prior_path = '..\\\\Module 6 - DataFrames and Spark SQL\\\\case study 1 dataset\\\\order_products__prior.csv'\n",
    "order_products_train_path = '..\\pyspark-training\\data\\df-exercise-1\\order_products__train.csv'\n",
    "orders_path = '..\\\\Module 6 - DataFrames and Spark SQL\\\\case study 1 dataset\\\\orders.csv'\n",
    "products_path = '..\\pyspark-training\\data\\df-exercise-1\\products.csv'\n",
    "\n",
    "df_aisles = spark.read.csv(aisles_path, inferSchema=True, header=True)\n",
    "df_departments = spark.read.csv(departments_path, inferSchema=True, header=True)\n",
    "df_order_products_prior = spark.read.csv(order_products_prior_path, inferSchema=True, header=True)\n",
    "df_order_products_train = spark.read.csv(order_products_train_path, inferSchema=True, header=True)\n",
    "df_orders = spark.read.csv(orders_path, inferSchema=True, header=True)\n",
    "df_products = spark.read.csv(products_path, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------+----------+---------+--------------------+--------------------+------------+\n",
      "|order_id|user_id|order_hour|product_id|reordered|        product_name|               aisle|  department|\n",
      "+--------+-------+----------+----------+---------+--------------------+--------------------+------------+\n",
      "|    2142|   2086|        16|     22823|        0|Roasted Bell Peppers|pickled goods olives|      pantry|\n",
      "|    8638|  57582|        18|     18339|        0|    100% Lemon Juice|       juice nectars|   beverages|\n",
      "|   19984| 122975|        10|     35752|        0|Hardwood SmokedCe...|hot dogs bacon sa...|meat seafood|\n",
      "|   22346| 134817|        13|      4605|        0|       Yellow Onions|    fresh vegetables|     produce|\n",
      "|   26623|  47715|        16|     32303|        0| Red Seedless Grapes|        fresh fruits|     produce|\n",
      "+--------+-------+----------+----------+---------+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_aisles.createOrReplaceTempView('aisles')\n",
    "df_departments.createOrReplaceTempView('departments')\n",
    "df_order_products_prior.createOrReplaceTempView('prior')\n",
    "df_order_products_train.createOrReplaceTempView('train')\n",
    "df_orders.createOrReplaceTempView('orders')\n",
    "df_products.createOrReplaceTempView('products')\n",
    "\n",
    "df_all = spark.sql(\"\"\"\n",
    "                    select d.*, p.product_name, a.aisle, dp.department                           \n",
    "                      from (select d.order_id, d.user_id, d.order_hour_of_day order_hour, p.product_id, p.reordered\n",
    "                              from orders d \n",
    "                              left join prior p \n",
    "                                on d.order_id = p.order_id \n",
    "                              where eval_set = \"prior\"\n",
    "                            \n",
    "                            UNION \n",
    "                            \n",
    "                            select d.order_id, d.user_id, d.order_hour_of_day order_hour, t.product_id, t.reordered \n",
    "                              from orders d \n",
    "                              left join train t \n",
    "                                on d.order_id = t.order_id \n",
    "                             where eval_set = \"train\") d\n",
    "                      left join products p\n",
    "                        on d.product_id = p.product_id\n",
    "                      left join aisles a\n",
    "                        on p.aisle_id = a.aisle_id\n",
    "                      left join departments dp\n",
    "                        on p.department_id = dp.department_id\n",
    "                    \"\"\").cache()\n",
    "df_all.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33819106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------+----------+---------+------------+-----+----------+\n",
      "|order_id|user_id|order_hour|product_id|reordered|product_name|aisle|department|\n",
      "+--------+-------+----------+----------+---------+------------+-----+----------+\n",
      "|       0|      0|         0|         0|        0|           0|    3|         3|\n",
      "+--------+-------+----------+----------+---------+------------+-----+----------+\n",
      "\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_all.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_all.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the most ordered products (top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        product_name| count|\n",
      "+--------------------+------+\n",
      "|              Banana|491291|\n",
      "|Bag of Organic Ba...|394930|\n",
      "|Organic Strawberries|275577|\n",
      "|Organic Baby Spinach|251705|\n",
      "|Organic Hass Avocado|220877|\n",
      "|     Organic Avocado|184224|\n",
      "|         Large Lemon|160792|\n",
      "|        Strawberries|149445|\n",
      "|               Limes|146660|\n",
      "|  Organic Whole Milk|142813|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "product_cnt = df_all.groupBy('product_name').count()\n",
    "#product_cnt.show()\n",
    "product_cnt.orderBy(product_cnt['count'].desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do people usually reorder the same previous ordered products?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|reordered|   count|\n",
      "+---------+--------+\n",
      "|        1|19955360|\n",
      "|        0|13863746|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.groupBy('reordered').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People usually reorder products than order new products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List most reordered products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        product_name| count|\n",
      "+--------------------+------+\n",
      "|              Banana|415166|\n",
      "|Bag of Organic Ba...|329275|\n",
      "|Organic Strawberries|214448|\n",
      "|Organic Baby Spinach|194939|\n",
      "|Organic Hass Avocado|176173|\n",
      "|     Organic Avocado|140270|\n",
      "|  Organic Whole Milk|118684|\n",
      "|         Large Lemon|112178|\n",
      "| Organic Raspberries|109688|\n",
      "|        Strawberries|104588|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_reordered_cnt = df_all.filter('reordered = 1').groupBy('product_name').count()\n",
    "product_reordered_cnt.orderBy(product_reordered_cnt['count'].desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most importatn department and aisle (by number of products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+\n",
      "|               aisle|   department|cnt_product|\n",
      "+--------------------+-------------+-----------+\n",
      "|             missing|      missing|       1258|\n",
      "|     candy chocolate|       snacks|       1246|\n",
      "|       ice cream ice|       frozen|       1091|\n",
      "|vitamins supplements|personal care|       1038|\n",
      "|              yogurt|   dairy eggs|       1026|\n",
      "|      chips pretzels|       snacks|        989|\n",
      "|                 tea|    beverages|        894|\n",
      "|     packaged cheese|   dairy eggs|        891|\n",
      "|        frozen meals|       frozen|        880|\n",
      "|       cookies cakes|       snacks|        874|\n",
      "+--------------------+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prod_by_dept_aisle = df_all.groupBy(['aisle', 'department']).agg(countDistinct('product_name').alias('cnt_product'))\n",
    "prod_by_dept_aisle.orderBy(prod_by_dept_aisle['cnt_product'].desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the top 10 departments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|     department|  count|\n",
      "+---------------+-------+\n",
      "|        produce|9888378|\n",
      "|     dairy eggs|5631067|\n",
      "|         snacks|3006412|\n",
      "|      beverages|2804175|\n",
      "|         frozen|2336858|\n",
      "|         pantry|1956819|\n",
      "|         bakery|1225181|\n",
      "|   canned goods|1114857|\n",
      "|           deli|1095540|\n",
      "|dry goods pasta| 905340|\n",
      "+---------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_orders = df_all.groupBy('department').count()\n",
    "dept_orders.orderBy(dept_orders['count'].desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List top 10 products ordered in the morning (6AM to 10AM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        product_name| count|\n",
      "+--------------------+------+\n",
      "|              Banana|130034|\n",
      "|Bag of Organic Ba...|103310|\n",
      "|Organic Strawberries| 70885|\n",
      "|Organic Baby Spinach| 61910|\n",
      "|Organic Hass Avocado| 54537|\n",
      "|     Organic Avocado| 44238|\n",
      "|        Strawberries| 39794|\n",
      "|         Large Lemon| 39366|\n",
      "|  Organic Whole Milk| 38608|\n",
      "| Organic Raspberries| 38489|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all = df_all.withColumn('order_hour_int', df_all['order_hour'].cast(IntegerType()))\n",
    "product_morning = df_all.filter((df_all['order_hour_int'] >= 6) & \n",
    "                                (df_all['order_hour_int'] <= 10)).groupBy('product_name').count()\n",
    "product_morning.orderBy(product_morning['count'].desc()).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
