{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch25 - Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"../pyspark-training/data/The-Definitive-Guide/retail-data/by-day/*.csv\")\\\n",
    "    .coalesce(5)\\\n",
    "    .where(\"Description IS NOT NULL\")\n",
    "fakeIntDF = spark.read.parquet(\"../pyspark-training/data/The-Definitive-Guide/simple-ml-integers\")\n",
    "simpleDF = spark.read.json(\"../pyspark-training/data/The-Definitive-Guide/simple-ml\")\n",
    "scaleDF = spark.read.parquet(\"../pyspark-training/data/The-Definitive-Guide/simple-ml-scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.cache()\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Transformers\n",
    "### RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+--------------------+-----+\n",
      "|color| lab|value1|            value2|            features|label|\n",
      "+-----+----+------+------------------+--------------------+-----+\n",
      "|green|good|     1|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n",
      "| blue| bad|     8|14.386294994851129|(10,[2,3,6,9],[8....|  0.0|\n",
      "| blue| bad|    12|14.386294994851129|(10,[2,3,6,9],[12...|  0.0|\n",
      "|green|good|    15| 38.97187133755819|(10,[1,2,3,5,8],[...|  1.0|\n",
      "|green|good|    12|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n",
      "|green| bad|    16|14.386294994851129|(10,[1,2,3,5,8],[...|  0.0|\n",
      "|  red|good|    35|14.386294994851129|(10,[0,2,3,4,7],[...|  1.0|\n",
      "|  red| bad|     1| 38.97187133755819|(10,[0,2,3,4,7],[...|  0.0|\n",
      "|  red| bad|     2|14.386294994851129|(10,[0,2,3,4,7],[...|  0.0|\n",
      "|  red| bad|    16|14.386294994851129|(10,[0,2,3,4,7],[...|  0.0|\n",
      "|  red|good|    45| 38.97187133755819|(10,[0,2,3,4,7],[...|  1.0|\n",
      "|green|good|     1|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n",
      "| blue| bad|     8|14.386294994851129|(10,[2,3,6,9],[8....|  0.0|\n",
      "| blue| bad|    12|14.386294994851129|(10,[2,3,6,9],[12...|  0.0|\n",
      "|green|good|    15| 38.97187133755819|(10,[1,2,3,5,8],[...|  1.0|\n",
      "|green|good|    12|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n",
      "|green| bad|    16|14.386294994851129|(10,[1,2,3,5,8],[...|  0.0|\n",
      "|  red|good|    35|14.386294994851129|(10,[0,2,3,4,7],[...|  1.0|\n",
      "|  red| bad|     1| 38.97187133755819|(10,[0,2,3,4,7],[...|  0.0|\n",
      "|  red| bad|     2|14.386294994851129|(10,[0,2,3,4,7],[...|  0.0|\n",
      "+-----+----+------+------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "supervised = RFormula(formula = \"lab ~ . + color:value1 + color:value2\")\n",
    "supervised.fit(simpleDF).transform(simpleDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import SQLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+\n",
      "|sum(Quantity)|count(1)|CustomerID|\n",
      "+-------------+--------+----------+\n",
      "|          197|      36|   15311.0|\n",
      "|          301|      21|   16539.0|\n",
      "|           32|       1|   15100.0|\n",
      "|          449|      20|   12583.0|\n",
      "|          112|       2|   15291.0|\n",
      "|          260|      14|   13767.0|\n",
      "|          165|       9|   17760.0|\n",
      "|           72|      23|   17905.0|\n",
      "|           60|       2|   17924.0|\n",
      "|           53|       7|   17420.0|\n",
      "|           93|       6|   16928.0|\n",
      "|           86|       5|   14496.0|\n",
      "|          108|      11|   13576.0|\n",
      "|          544|      11|   13408.0|\n",
      "|         1004|       6|   13694.0|\n",
      "|         2704|    1130|      null|\n",
      "|          173|      58|   17908.0|\n",
      "|           24|       4|   17572.0|\n",
      "|           39|       5|   16552.0|\n",
      "|          102|      15|   17377.0|\n",
      "+-------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "basicTransformation = SQLTransformer()\\\n",
    "    .setStatement(\"\"\"\n",
    "        SELECT sum(Quantity), count(*), CustomerID\n",
    "        FROM __THIS__\n",
    "        GROUP BY CustomerID\n",
    "    \"\"\")\n",
    "basicTransformation.transform(sales).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+------------------------------------+\n",
      "|int1|int2|int3|VectorAssembler_6f59846f2c54__output|\n",
      "+----+----+----+------------------------------------+\n",
      "|   1|   2|   3|                       [1.0,2.0,3.0]|\n",
      "|   4|   5|   6|                       [4.0,5.0,6.0]|\n",
      "|   7|   8|   9|                       [7.0,8.0,9.0]|\n",
      "+----+----+----+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va = VectorAssembler().setInputCols([\"int1\", \"int2\", \"int3\"])\n",
    "va.transform(fakeIntDF).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Continuous Features\n",
    "### Bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "contDF = spark.range(20).selectExpr(\"cast(id as double)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------------+\n",
      "|  id|Bucketizer_8ea7704365f0__output|\n",
      "+----+-------------------------------+\n",
      "| 0.0|                            0.0|\n",
      "| 1.0|                            0.0|\n",
      "| 2.0|                            0.0|\n",
      "| 3.0|                            0.0|\n",
      "| 4.0|                            0.0|\n",
      "| 5.0|                            1.0|\n",
      "| 6.0|                            1.0|\n",
      "| 7.0|                            1.0|\n",
      "| 8.0|                            1.0|\n",
      "| 9.0|                            1.0|\n",
      "|10.0|                            2.0|\n",
      "|11.0|                            2.0|\n",
      "|12.0|                            2.0|\n",
      "|13.0|                            2.0|\n",
      "|14.0|                            2.0|\n",
      "|15.0|                            2.0|\n",
      "|16.0|                            2.0|\n",
      "|17.0|                            2.0|\n",
      "|18.0|                            2.0|\n",
      "|19.0|                            2.0|\n",
      "+----+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucketBorders = [-1.0, 5.0, 10.0, 250.0, 600.0]\n",
    "bucketer = Bucketizer().setSplits(bucketBorders).setInputCol(\"id\")\n",
    "bucketer.transform(contDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucketer = QuantileDiscretizer().setNumBuckets(5).setInputCol(\"id\")\n",
    "# fittedBucketer = bucketer.fit(contDF)\n",
    "# fittedBucketer.transform(contDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-----------------------------------+\n",
      "| id|      features|StandardScaler_cabf1725b926__output|\n",
      "+---+--------------+-----------------------------------+\n",
      "|  0|[1.0,0.1,-1.0]|               [1.19522860933439...|\n",
      "|  1| [2.0,1.1,1.0]|               [2.39045721866878...|\n",
      "|  0|[1.0,0.1,-1.0]|               [1.19522860933439...|\n",
      "|  1| [2.0,1.1,1.0]|               [2.39045721866878...|\n",
      "|  1|[3.0,10.1,3.0]|               [3.58568582800318...|\n",
      "+---+--------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().setInputCol(\"features\")\n",
    "scaler.fit(scaleDF).transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+---------------------------------+\n",
      "| id|      features|MinMaxScaler_00afcdc279ef__output|\n",
      "+---+--------------+---------------------------------+\n",
      "|  0|[1.0,0.1,-1.0]|                    [0.0,0.0,0.0]|\n",
      "|  1| [2.0,1.1,1.0]|                    [0.5,0.1,0.5]|\n",
      "|  0|[1.0,0.1,-1.0]|                    [0.0,0.0,0.0]|\n",
      "|  1| [2.0,1.1,1.0]|                    [0.5,0.1,0.5]|\n",
      "|  1|[3.0,10.1,3.0]|                    [1.0,1.0,1.0]|\n",
      "+---+--------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minMax = MinMaxScaler().setInputCol(\"features\")\n",
    "minMax.fit(scaleDF).transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+---------------------------------+\n",
      "| id|      features|MaxAbsScaler_2e6fdf33a809__output|\n",
      "+---+--------------+---------------------------------+\n",
      "|  0|[1.0,0.1,-1.0]|             [0.33333333333333...|\n",
      "|  1| [2.0,1.1,1.0]|             [0.66666666666666...|\n",
      "|  0|[1.0,0.1,-1.0]|             [0.33333333333333...|\n",
      "|  1| [2.0,1.1,1.0]|             [0.66666666666666...|\n",
      "|  1|[3.0,10.1,3.0]|                    [1.0,1.0,1.0]|\n",
      "+---+--------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maScaler = MaxAbsScaler().setInputCol(\"features\")\n",
    "maScaler.fit(scaleDF).transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Categorical Features\n",
    "### StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+--------+\n",
      "|color| lab|value1|            value2|labeling|\n",
      "+-----+----+------+------------------+--------+\n",
      "|green|good|     1|14.386294994851129|     1.0|\n",
      "| blue| bad|     8|14.386294994851129|     0.0|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|\n",
      "|green|good|    15| 38.97187133755819|     1.0|\n",
      "|green|good|    12|14.386294994851129|     1.0|\n",
      "|green| bad|    16|14.386294994851129|     0.0|\n",
      "|  red|good|    35|14.386294994851129|     1.0|\n",
      "|  red| bad|     1| 38.97187133755819|     0.0|\n",
      "|  red| bad|     2|14.386294994851129|     0.0|\n",
      "|  red| bad|    16|14.386294994851129|     0.0|\n",
      "|  red|good|    45| 38.97187133755819|     1.0|\n",
      "|green|good|     1|14.386294994851129|     1.0|\n",
      "| blue| bad|     8|14.386294994851129|     0.0|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|\n",
      "|green|good|    15| 38.97187133755819|     1.0|\n",
      "|green|good|    12|14.386294994851129|     1.0|\n",
      "|green| bad|    16|14.386294994851129|     0.0|\n",
      "|  red|good|    35|14.386294994851129|     1.0|\n",
      "|  red| bad|     1| 38.97187133755819|     0.0|\n",
      "|  red| bad|     2|14.386294994851129|     0.0|\n",
      "+-----+----+------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lblIndxr = StringIndexer().setInputCol(\"lab\").setOutputCol(\"labeling\")\n",
    "idxRes = lblIndxr.fit(simpleDF).transform(simpleDF)\n",
    "idxRes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Indexed Values Back to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+--------+----------------------------------+\n",
      "|color| lab|value1|            value2|labeling|IndexToString_7ca09f65b4c6__output|\n",
      "+-----+----+------+------------------+--------+----------------------------------+\n",
      "|green|good|     1|14.386294994851129|     1.0|                              good|\n",
      "| blue| bad|     8|14.386294994851129|     0.0|                               bad|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|                               bad|\n",
      "|green|good|    15| 38.97187133755819|     1.0|                              good|\n",
      "|green|good|    12|14.386294994851129|     1.0|                              good|\n",
      "|green| bad|    16|14.386294994851129|     0.0|                               bad|\n",
      "|  red|good|    35|14.386294994851129|     1.0|                              good|\n",
      "|  red| bad|     1| 38.97187133755819|     0.0|                               bad|\n",
      "|  red| bad|     2|14.386294994851129|     0.0|                               bad|\n",
      "|  red| bad|    16|14.386294994851129|     0.0|                               bad|\n",
      "|  red|good|    45| 38.97187133755819|     1.0|                              good|\n",
      "|green|good|     1|14.386294994851129|     1.0|                              good|\n",
      "| blue| bad|     8|14.386294994851129|     0.0|                               bad|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|                               bad|\n",
      "|green|good|    15| 38.97187133755819|     1.0|                              good|\n",
      "|green|good|    12|14.386294994851129|     1.0|                              good|\n",
      "|green| bad|    16|14.386294994851129|     0.0|                               bad|\n",
      "|  red|good|    35|14.386294994851129|     1.0|                              good|\n",
      "|  red| bad|     1| 38.97187133755819|     0.0|                               bad|\n",
      "|  red| bad|     2|14.386294994851129|     0.0|                               bad|\n",
      "+-----+----+------+------------------+--------+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IndexToString().setInputCol(\"labeling\").transform(idxRes).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----------------------------------+\n",
      "|color|colorInd|OneHotEncoder_e9b35ae4530c__output|\n",
      "+-----+--------+----------------------------------+\n",
      "|green|     1.0|                     (2,[1],[1.0])|\n",
      "| blue|     2.0|                         (2,[],[])|\n",
      "| blue|     2.0|                         (2,[],[])|\n",
      "|green|     1.0|                     (2,[1],[1.0])|\n",
      "|green|     1.0|                     (2,[1],[1.0])|\n",
      "|green|     1.0|                     (2,[1],[1.0])|\n",
      "|  red|     0.0|                     (2,[0],[1.0])|\n",
      "|  red|     0.0|                     (2,[0],[1.0])|\n",
      "|  red|     0.0|                     (2,[0],[1.0])|\n",
      "|  red|     0.0|                     (2,[0],[1.0])|\n",
      "|  red|     0.0|                     (2,[0],[1.0])|\n",
      "|green|     1.0|                     (2,[1],[1.0])|\n",
      "| blue|     2.0|                         (2,[],[])|\n",
      "| blue|     2.0|                         (2,[],[])|\n",
      "|green|     1.0|                     (2,[1],[1.0])|\n",
      "|green|     1.0|                     (2,[1],[1.0])|\n",
      "|green|     1.0|                     (2,[1],[1.0])|\n",
      "|  red|     0.0|                     (2,[0],[1.0])|\n",
      "|  red|     0.0|                     (2,[0],[1.0])|\n",
      "|  red|     0.0|                     (2,[0],[1.0])|\n",
      "+-----+--------+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lblIndxr = StringIndexer().setInputCol(\"color\").setOutputCol(\"colorInd\")\n",
    "colorLab = lblIndxr.fit(simpleDF).transform(simpleDF.select(\"color\"))\n",
    "ohe = OneHotEncoder().setInputCol(\"colorInd\")\n",
    "ohe.transform(colorLab).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data Transformers \n",
    "### Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------------------------------+\n",
      "|Description                        |DescOut                                   |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER |[white, hanging, heart, t-light, holder]  |\n",
      "|WHITE METAL LANTERN                |[white, metal, lantern]                   |\n",
      "|CREAM CUPID HEARTS COAT HANGER     |[cream, cupid, hearts, coat, hanger]      |\n",
      "|KNITTED UNION FLAG HOT WATER BOTTLE|[knitted, union, flag, hot, water, bottle]|\n",
      "|RED WOOLLY HOTTIE WHITE HEART.     |[red, woolly, hottie, white, heart.]      |\n",
      "|SET 7 BABUSHKA NESTING BOXES       |[set, 7, babushka, nesting, boxes]        |\n",
      "|GLASS STAR FROSTED T-LIGHT HOLDER  |[glass, star, frosted, t-light, holder]   |\n",
      "|HAND WARMER UNION JACK             |[hand, warmer, union, jack]               |\n",
      "|HAND WARMER RED POLKA DOT          |[hand, warmer, red, polka, dot]           |\n",
      "|ASSORTED COLOUR BIRD ORNAMENT      |[assorted, colour, bird, ornament]        |\n",
      "|POPPY'S PLAYHOUSE BEDROOM          |[poppy's, playhouse, bedroom]             |\n",
      "|POPPY'S PLAYHOUSE KITCHEN          |[poppy's, playhouse, kitchen]             |\n",
      "|FELTCRAFT PRINCESS CHARLOTTE DOLL  |[feltcraft, princess, charlotte, doll]    |\n",
      "|IVORY KNITTED MUG COSY             |[ivory, knitted, mug, cosy]               |\n",
      "|BOX OF 6 ASSORTED COLOUR TEASPOONS |[box, of, 6, assorted, colour, teaspoons] |\n",
      "|BOX OF VINTAGE JIGSAW BLOCKS       |[box, of, vintage, jigsaw, blocks]        |\n",
      "|BOX OF VINTAGE ALPHABET BLOCKS     |[box, of, vintage, alphabet, blocks]      |\n",
      "|HOME BUILDING BLOCK WORD           |[home, building, block, word]             |\n",
      "|LOVE BUILDING BLOCK WORD           |[love, building, block, word]             |\n",
      "|RECIPE BOX WITH METAL HEART        |[recipe, box, with, metal, heart]         |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tkn = Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\n",
    "tokenized = tkn.transform(sales.select(\"Description\"))\n",
    "tokenized.show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|         Description|             DescOut|            DescOut2|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|WHITE HANGING HEA...|[white, hanging, ...|[white, hanging, ...|\n",
      "| WHITE METAL LANTERN|[white, metal, la...|[white, metal, la...|\n",
      "|CREAM CUPID HEART...|[cream, cupid, he...|[cream, cupid, he...|\n",
      "|KNITTED UNION FLA...|[knitted, union, ...|[knitted, union, ...|\n",
      "|RED WOOLLY HOTTIE...|[red, woolly, hot...|[red, woolly, hot...|\n",
      "|SET 7 BABUSHKA NE...|[set, 7, babushka...|[set, 7, babushka...|\n",
      "|GLASS STAR FROSTE...|[glass, star, fro...|[glass, star, fro...|\n",
      "|HAND WARMER UNION...|[hand, warmer, un...|[hand, warmer, un...|\n",
      "|HAND WARMER RED P...|[hand, warmer, re...|[hand, warmer, re...|\n",
      "|ASSORTED COLOUR B...|[assorted, colour...|[assorted, colour...|\n",
      "|POPPY'S PLAYHOUSE...|[poppy's, playhou...|[poppy's, playhou...|\n",
      "|POPPY'S PLAYHOUSE...|[poppy's, playhou...|[poppy's, playhou...|\n",
      "|FELTCRAFT PRINCES...|[feltcraft, princ...|[feltcraft, princ...|\n",
      "|IVORY KNITTED MUG...|[ivory, knitted, ...|[ivory, knitted, ...|\n",
      "|BOX OF 6 ASSORTED...|[box, of, 6, asso...|[box, 6, assorted...|\n",
      "|BOX OF VINTAGE JI...|[box, of, vintage...|[box, vintage, ji...|\n",
      "|BOX OF VINTAGE AL...|[box, of, vintage...|[box, vintage, al...|\n",
      "|HOME BUILDING BLO...|[home, building, ...|[home, building, ...|\n",
      "|LOVE BUILDING BLO...|[love, building, ...|[love, building, ...|\n",
      "|RECIPE BOX WITH M...|[recipe, box, wit...|[recipe, box, met...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "stops = StopWordsRemover()\\\n",
    "    .setStopWords(englishStopWords)\\\n",
    "    .setInputCol(\"DescOut\")\\\n",
    "    .setOutputCol(\"DescOut2\")\n",
    "tokenized = stops.transform(tokenized)\n",
    "tokenized.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Words into Numerical Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|         Description|             DescOut|            DescOut2|            countVec|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|WHITE HANGING HEA...|[white, hanging, ...|[white, hanging, ...|(932,[3,9,16,22,2...|\n",
      "| WHITE METAL LANTERN|[white, metal, la...|[white, metal, la...|(932,[9,17,196],[...|\n",
      "|CREAM CUPID HEART...|[cream, cupid, he...|[cream, cupid, he...|(932,[46,90,127,1...|\n",
      "|KNITTED UNION FLA...|[knitted, union, ...|[knitted, union, ...|(932,[12,13,14,56...|\n",
      "|RED WOOLLY HOTTIE...|[red, woolly, hot...|[red, woolly, hot...|(932,[0,9,198,204...|\n",
      "|SET 7 BABUSHKA NE...|[set, 7, babushka...|[set, 7, babushka...|(932,[1,38,63,288...|\n",
      "|GLASS STAR FROSTE...|[glass, star, fro...|[glass, star, fro...|(932,[16,24,26,43...|\n",
      "|HAND WARMER UNION...|[hand, warmer, un...|[hand, warmer, un...|(932,[20,23,56,10...|\n",
      "|HAND WARMER RED P...|[hand, warmer, re...|[hand, warmer, re...|(932,[0,20,23,414...|\n",
      "|ASSORTED COLOUR B...|[assorted, colour...|[assorted, colour...|(932,[48,58,80,34...|\n",
      "|POPPY'S PLAYHOUSE...|[poppy's, playhou...|[poppy's, playhou...|(932,[273,283,616...|\n",
      "|POPPY'S PLAYHOUSE...|[poppy's, playhou...|[poppy's, playhou...|(932,[145,273,283...|\n",
      "|FELTCRAFT PRINCES...|[feltcraft, princ...|[feltcraft, princ...|(932,[35,131,155,...|\n",
      "|IVORY KNITTED MUG...|[ivory, knitted, ...|[ivory, knitted, ...|(932,[27,67,94,19...|\n",
      "|BOX OF 6 ASSORTED...|[box, of, 6, asso...|[box, 6, assorted...|(932,[5,28,48,80,...|\n",
      "|BOX OF VINTAGE JI...|[box, of, vintage...|[box, vintage, ji...|(932,[5,8,167,418...|\n",
      "|BOX OF VINTAGE AL...|[box, of, vintage...|[box, vintage, al...|(932,[5,8,418,426...|\n",
      "|HOME BUILDING BLO...|[home, building, ...|[home, building, ...|(932,[75,105,177,...|\n",
      "|LOVE BUILDING BLO...|[love, building, ...|[love, building, ...|(932,[60,105,177,...|\n",
      "|RECIPE BOX WITH M...|[recipe, box, wit...|[recipe, box, met...|(932,[3,5,17,163]...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\\\n",
    "    .setInputCol(\"DescOut2\")\\\n",
    "    .setOutputCol(\"countVec\")\\\n",
    "    .setMinTF(1)\\\n",
    "    .setMinDF(2)\n",
    "fittedCV = cv.fit(tokenized)\n",
    "fittedCV.transform(tokenized).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "Term frequency - inverse ducoment frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|DescOut                             |\n",
      "+------------------------------------+\n",
      "|[red, woolly, hottie, white, heart.]|\n",
      "|[hand, warmer, red, polka, dot]     |\n",
      "|[red, coat, rack, paris, fashion]   |\n",
      "|[alarm, clock, bakelike, red]       |\n",
      "|[set/2, red, retrospot, tea, towels]|\n",
      "|[red, toadstool, led, night, light] |\n",
      "|[hand, warmer, red, polka, dot]     |\n",
      "|[edwardian, parasol, red]           |\n",
      "|[red, woolly, hottie, white, heart.]|\n",
      "|[edwardian, parasol, red]           |\n",
      "+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfIdfIn = tokenized\\\n",
    "    .where(\"array_contains(DescOut, 'red')\")\\\n",
    "    .select(\"DescOut\")\\\n",
    "    .limit(10)\n",
    "tfIdfIn.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|DescOut                             |TFOut                                                             |IDFOut                                                                                                                        |\n",
      "+------------------------------------+------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[red, woolly, hottie, white, heart.]|(262144,[30600,57341,81060,100086,195459],[1.0,1.0,1.0,1.0,1.0])  |(262144,[30600,57341,81060,100086,195459],[1.2992829841302609,1.2992829841302609,1.2992829841302609,1.2992829841302609,0.0])  |\n",
      "|[hand, warmer, red, polka, dot]     |(262144,[58545,167356,178320,195459,232367],[1.0,1.0,1.0,1.0,1.0])|(262144,[58545,167356,178320,195459,232367],[1.2992829841302609,1.2992829841302609,1.2992829841302609,0.0,1.2992829841302609])|\n",
      "|[red, coat, rack, paris, fashion]   |(262144,[1133,62187,87922,106054,195459],[1.0,1.0,1.0,1.0,1.0])   |(262144,[1133,62187,87922,106054,195459],[0.0,0.0,0.0,0.0,0.0])                                                               |\n",
      "|[alarm, clock, bakelike, red]       |(262144,[3028,157892,178019,195459],[1.0,1.0,1.0,1.0])            |(262144,[3028,157892,178019,195459],[0.0,0.0,0.0,0.0])                                                                        |\n",
      "|[set/2, red, retrospot, tea, towels]|(262144,[56171,127412,180780,182751,195459],[1.0,1.0,1.0,1.0,1.0])|(262144,[56171,127412,180780,182751,195459],[0.0,0.0,0.0,0.0,0.0])                                                            |\n",
      "|[red, toadstool, led, night, light] |(262144,[17670,34036,66092,81671,195459],[1.0,1.0,1.0,1.0,1.0])   |(262144,[17670,34036,66092,81671,195459],[0.0,0.0,0.0,0.0,0.0])                                                               |\n",
      "|[hand, warmer, red, polka, dot]     |(262144,[58545,167356,178320,195459,232367],[1.0,1.0,1.0,1.0,1.0])|(262144,[58545,167356,178320,195459,232367],[1.2992829841302609,1.2992829841302609,1.2992829841302609,0.0,1.2992829841302609])|\n",
      "|[edwardian, parasol, red]           |(262144,[86664,127570,195459],[1.0,1.0,1.0])                      |(262144,[86664,127570,195459],[1.2992829841302609,1.2992829841302609,0.0])                                                    |\n",
      "|[red, woolly, hottie, white, heart.]|(262144,[30600,57341,81060,100086,195459],[1.0,1.0,1.0,1.0,1.0])  |(262144,[30600,57341,81060,100086,195459],[1.2992829841302609,1.2992829841302609,1.2992829841302609,1.2992829841302609,0.0])  |\n",
      "|[edwardian, parasol, red]           |(262144,[86664,127570,195459],[1.0,1.0,1.0])                      |(262144,[86664,127570,195459],[1.2992829841302609,1.2992829841302609,0.0])                                                    |\n",
      "+------------------------------------+------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "tf = HashingTF().setInputCol(\"DescOut\").setOutputCol(\"TFOut\")\n",
    "idf = IDF().setInputCol(\"TFOut\").setOutputCol(\"IDFOut\").setMinDocFreq(2)\n",
    "idf.fit(tf.transform(tfIdfIn)).transform(tf.transform(tfIdfIn)).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Manipulation\n",
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+------------------------------------------+\n",
      "|id |features      |PCA_7065d5216223__output                  |\n",
      "+---+--------------+------------------------------------------+\n",
      "|0  |[1.0,0.1,-1.0]|[0.07137194992484153,-0.45266548881478463]|\n",
      "|1  |[2.0,1.1,1.0] |[-1.6804946984073725,1.2593401322219144]  |\n",
      "|0  |[1.0,0.1,-1.0]|[0.07137194992484153,-0.45266548881478463]|\n",
      "|1  |[2.0,1.1,1.0] |[-1.6804946984073725,1.2593401322219144]  |\n",
      "|1  |[3.0,10.1,3.0]|[-10.872398139848944,0.030962697060149758]|\n",
      "+---+--------------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "pca = PCA().setInputCol(\"features\").setK(2)\n",
    "pca.fit(scaleDF).transform(scaleDF).show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-----------------------------------------------------------------------------------+\n",
      "|id |features      |PolynomialExpansion_5578bbcd1530__output                                           |\n",
      "+---+--------------+-----------------------------------------------------------------------------------+\n",
      "|0  |[1.0,0.1,-1.0]|[1.0,1.0,0.1,0.1,0.010000000000000002,-1.0,-1.0,-0.1,1.0]                          |\n",
      "|1  |[2.0,1.1,1.0] |[2.0,4.0,1.1,2.2,1.2100000000000002,1.0,2.0,1.1,1.0]                               |\n",
      "|0  |[1.0,0.1,-1.0]|[1.0,1.0,0.1,0.1,0.010000000000000002,-1.0,-1.0,-0.1,1.0]                          |\n",
      "|1  |[2.0,1.1,1.0] |[2.0,4.0,1.1,2.2,1.2100000000000002,1.0,2.0,1.1,1.0]                               |\n",
      "|1  |[3.0,10.1,3.0]|[3.0,9.0,10.1,30.299999999999997,102.00999999999999,3.0,9.0,30.299999999999997,9.0]|\n",
      "+---+--------------+-----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "pe = PolynomialExpansion().setInputCol(\"features\").setDegree(2)\n",
    "pe.transform(scaleDF).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "### ChiSqSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------------------------+\n",
      "|             DescOut|            countVec|ChiSqSelector_00ea411af33c__output|\n",
      "+--------------------+--------------------+----------------------------------+\n",
      "|[white, hanging, ...|(709,[4,8,16,23,2...|                         (2,[],[])|\n",
      "|[white, metal, la...|(709,[8,25,159],[...|                         (2,[],[])|\n",
      "|[cream, cupid, he...|(709,[49,97,109,1...|                         (2,[],[])|\n",
      "|[knitted, union, ...|(709,[10,11,12,52...|                         (2,[],[])|\n",
      "|[red, woolly, hot...|(709,[0,8,171,174...|                         (2,[],[])|\n",
      "|[set, 7, babushka...|(709,[1,37,58,220...|                         (2,[],[])|\n",
      "|[glass, star, fro...|(709,[16,24,31,42...|                         (2,[],[])|\n",
      "|[hand, warmer, un...|(709,[17,18,52,90...|                         (2,[],[])|\n",
      "|[hand, warmer, re...|(709,[0,17,18,298...|                         (2,[],[])|\n",
      "|[assorted, colour...|(709,[53,61,88,24...|                         (2,[],[])|\n",
      "|[poppy's, playhou...|(709,[384,448,672...|                         (2,[],[])|\n",
      "|[poppy's, playhou...|(709,[234,384,448...|                         (2,[],[])|\n",
      "|[feltcraft, princ...|(709,[33,118,163,...|                         (2,[],[])|\n",
      "|[ivory, knitted, ...|(709,[43,78,99,19...|                         (2,[],[])|\n",
      "|[box, of, 6, asso...|(709,[2,6,30,53,8...|                         (2,[],[])|\n",
      "|[box, of, vintage...|(709,[2,6,13,198,...|                         (2,[],[])|\n",
      "|[box, of, vintage...|(709,[2,6,13,342,...|                         (2,[],[])|\n",
      "|[home, building, ...|(709,[77,87,153,1...|                         (2,[],[])|\n",
      "|[love, building, ...|(709,[67,87,153,1...|                         (2,[],[])|\n",
      "|[recipe, box, wit...|(709,[4,6,25,34,1...|                         (2,[],[])|\n",
      "+--------------------+--------------------+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "tkn = Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\n",
    "tokenized = tkn.transform(sales.select(\"Description\", \"CustomerId\")).where(\"CustomerId IS NOT NULL\")\n",
    "\n",
    "# Count Vectorizer\n",
    "cv = CountVectorizer().setInputCol(\"DescOut\").setOutputCol(\"countVec\").setMinTF(1).setMinDF(2)\n",
    "fittedCV = cv.fit(tokenized)\n",
    "\n",
    "# ChiSqSelector\n",
    "prechi = fittedCV.transform(tokenized).where(\"customerID IS NOT NULL\")\n",
    "chisq = ChiSqSelector().setFeaturesCol(\"countVec\").setLabelCol(\"CustomerId\").setNumTopFeatures(2)\n",
    "chisq.fit(prechi).transform(prechi).drop(\"customerID\", \"Description\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
