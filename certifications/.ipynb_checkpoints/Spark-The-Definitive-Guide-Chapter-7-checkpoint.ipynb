{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 - Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"../pyspark-training/data/The-Definitive-Guide/retail-data/all/*.csv\")\\\n",
    "    .coalesce(5)\n",
    "df.cache()\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count() is a method and an action here\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Functions\n",
    "### Note: These aggregation functions are used with `select()` and take a string as the argument rather than col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, countDistinct, approx_count_distinct, first, last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------+--------------------------------+-----------------------+----------------------+\n",
      "|count(StockCode)|count(DISTINCT StockCode)|approx_count_distinct(StockCode)|first(StockCode, false)|last(StockCode, false)|\n",
      "+----------------+-------------------------+--------------------------------+-----------------------+----------------------+\n",
      "|          541909|                     4070|                            3364|                  20868|                 90149|\n",
      "+----------------+-------------------------+--------------------------------+-----------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count() is a function here\n",
    "df.select(count(\"StockCode\"),\n",
    "          countDistinct(\"StockCode\"),\n",
    "          approx_count_distinct(\"StockCode\", 0.1),\n",
    "          first(\"StockCode\"),\n",
    "          last(\"StockCode\"),\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max, sum, sumDistinct, avg, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------+----------------------+----------------+----------------+\n",
      "|min(Quantity)|max(Quantity)|sum(Quantity)|sum(DISTINCT Quantity)|   avg(Quantity)|   avg(Quantity)|\n",
      "+-------------+-------------+-------------+----------------------+----------------+----------------+\n",
      "|       -80995|        80995|      5176450|                 29310|9.55224954743324|9.55224954743324|\n",
      "+-------------+-------------+-------------+----------------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min(\"Quantity\"),\n",
    "          max(\"Quantity\"),\n",
    "          sum(\"Quantity\"),\n",
    "          sumDistinct(\"Quantity\"),\n",
    "          avg(\"Quantity\"),\n",
    "          expr(\"mean(Quantity)\")\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import variance, stddev, var_pop, stddev_pop, var_samp, stddev_samp, skewness, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|               var|           var_pop|          var_samp|            stddev|        stddev_pop|       stddev_samp|\n",
      "+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|47559.391409298754|47559.303646609056|47559.391409298754|218.08115785023418|218.08095663447796|218.08115785023418|\n",
      "+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(variance(\"Quantity\").alias(\"var\"),\n",
    "          var_pop(\"Quantity\").alias(\"var_pop\"),\n",
    "          var_samp(\"Quantity\").alias(\"var_samp\"),\n",
    "          stddev(\"Quantity\").alias(\"stddev\"),\n",
    "          stddev_pop(\"Quantity\").alias(\"stddev_pop\"),\n",
    "          stddev_samp(\"Quantity\").alias(\"stddev_samp\")\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|           skewness|          kurtosis|\n",
      "+-------------------+------------------+\n",
      "|-0.2640755761052562|119768.05495536952|\n",
      "+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(skewness(\"Quantity\").alias(\"skewness\"),\n",
    "          kurtosis(\"Quantity\").alias(\"kurtosis\")\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr, covar_pop, covar_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|corr(InvoiceNo, Quantity)|covar_samp(InvoiceNo, Quantity)|covar_pop(InvoiceNo, Quantity)|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|     4.912186085635685E-4|             1052.7280543902734|            1052.7260778741693|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr(\"InvoiceNo\", \"Quantity\"),\n",
    "          covar_samp(\"InvoiceNo\", \"Quantity\"),\n",
    "          covar_pop(\"InvoiceNo\", \"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_set, collect_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE the `agg()` method is used here when aggregating to complex types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|collect_set(Country)|collect_list(Country)|\n",
      "+--------------------+---------------------+\n",
      "|[Portugal, Italy,...| [United Kingdom, ...|\n",
      "+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(collect_set(\"Country\"), collect_list(\"Country\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+\n",
      "|InvoiceNo|CustomerId|count|\n",
      "+---------+----------+-----+\n",
      "|   536846|     14573|   76|\n",
      "|   537026|     12395|   12|\n",
      "+---------+----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Special case: use count() as a method'\n",
    "df.groupBy(\"InvoiceNo\", \"CustomerId\").count().show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `agg()` instead of `select()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------------+\n",
      "|InvoiceNo|quan|count(Quantity)|\n",
      "+---------+----+---------------+\n",
      "|   536596|   6|              6|\n",
      "|   536938|  14|             14|\n",
      "+---------+----+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg(\n",
    "    count(\"Quantity\").alias(\"quan\"),\n",
    "    expr(\"count(Quantity)\")\n",
    ").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+--------------------+\n",
      "|InvoiceNo|     avg(Quantity)|stddev_pop(Quantity)|\n",
      "+---------+------------------+--------------------+\n",
      "|   536596|               1.5|  1.1180339887498947|\n",
      "|   536938|33.142857142857146|  20.698023172885524|\n",
      "+---------+------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg(expr(\"avg(Quantity)\"),\n",
    "                            expr(\"stddev_pop(Quantity)\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, desc, dense_rank, rank\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+------------+-----------------+-------------------+\n",
      "|CustomerId|      date|Quantity|quantityRank|quantityDenseRank|maxPurchaseQuantity|\n",
      "+----------+----------+--------+------------+-----------------+-------------------+\n",
      "|     12346|2011-01-18|   74215|           1|                1|              74215|\n",
      "|     12346|2011-01-18|  -74215|           2|                2|              74215|\n",
      "|     12347|2010-12-07|      36|           1|                1|                 36|\n",
      "|     12347|2010-12-07|      30|           2|                2|                 36|\n",
      "|     12347|2010-12-07|      24|           3|                3|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|      12|           4|                4|                 36|\n",
      "|     12347|2010-12-07|       6|          17|                5|                 36|\n",
      "|     12347|2010-12-07|       6|          17|                5|                 36|\n",
      "+----------+----------+--------+------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create date column\n",
    "dfWithDate = df.withColumn(\"date\", to_date(col(\"InvoiceDate\"), 'MM/dd/yyyy HH:mm'))\n",
    "\n",
    "# Create a window specification\n",
    "    # Note that Window object is created here\n",
    "windowSpec = Window\\\n",
    "    .partitionBy(\"CustomerId\", \"date\")\\\n",
    "    .orderBy(desc(\"Quantity\"))\\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow) # Note the attribute of Window object here\n",
    "\n",
    "# Apply functions with the Window specification\n",
    "# The output is a column\n",
    "maxPurchaseQuantity = max(col(\"Quantity\")).over(windowSpec)\n",
    "    # dense_rank and rank are done within partitions\n",
    "purchaseDenseRank = dense_rank().over(windowSpec)\n",
    "purchaseRank = rank().over(windowSpec)\n",
    "\n",
    "# Get the final output as DataFrame\n",
    "dfWithDate.where(\"CustomerId IS NOT NULL\").orderBy(\"CustomerId\")\\\n",
    "    .select(col(\"CustomerId\"),\n",
    "            col(\"date\"),\n",
    "            col(\"Quantity\"),\n",
    "            # pass on the columns with windows grouping\n",
    "            purchaseRank.alias(\"quantityRank\"),\n",
    "            purchaseDenseRank.alias(\"quantityDenseRank\"),\n",
    "            maxPurchaseQuantity.alias(\"maxPurchaseQuantity\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rollups\n",
    "Grouping with total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+\n",
      "|      date|       Country|total_quantity|\n",
      "+----------+--------------+--------------+\n",
      "|      null|          null|       5176450|\n",
      "|2010-12-01|        France|           449|\n",
      "|2010-12-01|          EIRE|           243|\n",
      "|2010-12-01|          null|         26814|\n",
      "|2010-12-01|       Germany|           117|\n",
      "|2010-12-01|United Kingdom|         23949|\n",
      "|2010-12-01|   Netherlands|            97|\n",
      "|2010-12-01|     Australia|           107|\n",
      "|2010-12-01|        Norway|          1852|\n",
      "|2010-12-02|       Germany|           146|\n",
      "|2010-12-02|          EIRE|             4|\n",
      "|2010-12-02|          null|         21023|\n",
      "|2010-12-02|United Kingdom|         20873|\n",
      "|2010-12-03|        Poland|           140|\n",
      "|2010-12-03|   Switzerland|           110|\n",
      "|2010-12-03|       Germany|           170|\n",
      "|2010-12-03|      Portugal|            65|\n",
      "|2010-12-03|         Spain|           400|\n",
      "|2010-12-03|         Italy|           164|\n",
      "|2010-12-03|       Belgium|           528|\n",
      "+----------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithDate.rollup(\"date\", \"Country\").agg(sum(\"Quantity\"))\\\n",
    "    .selectExpr(\"date\", \"Country\", \"`sum(Quantity)` as total_quantity\")\\\n",
    "    .orderBy(\"date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cube\n",
    "Grouping with subtotals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------+\n",
      "|      Date|             Country|sum(Quantity)|\n",
      "+----------+--------------------+-------------+\n",
      "|      null|        Saudi Arabia|           75|\n",
      "|      null|              Sweden|        35637|\n",
      "|      null|           Australia|        83653|\n",
      "|      null|              Israel|         4353|\n",
      "|      null|             Finland|        10666|\n",
      "|      null|              Poland|         3653|\n",
      "|      null|                EIRE|       142637|\n",
      "|      null|              Canada|         2763|\n",
      "|      null|      United Kingdom|      4263829|\n",
      "|      null|              France|       110480|\n",
      "|      null|             Belgium|        23152|\n",
      "|      null|              Greece|         1556|\n",
      "|      null|              Brazil|          356|\n",
      "|      null|                 RSA|          352|\n",
      "|      null|                 USA|         1034|\n",
      "|      null|              Cyprus|         6317|\n",
      "|      null|           Hong Kong|         4769|\n",
      "|      null|               Italy|         7999|\n",
      "|      null|  European Community|          497|\n",
      "|      null|     Channel Islands|         9479|\n",
      "|      null|      Czech Republic|          592|\n",
      "|      null|         Netherlands|       200128|\n",
      "|      null|           Lithuania|          652|\n",
      "|      null|             Iceland|         2458|\n",
      "|      null|United Arab Emirates|          982|\n",
      "|      null|             Lebanon|          386|\n",
      "|      null|             Austria|         4827|\n",
      "|      null|             Germany|       117448|\n",
      "|      null|         Switzerland|        30325|\n",
      "|      null|                null|      5176450|\n",
      "|      null|               Malta|          944|\n",
      "|      null|              Norway|        19247|\n",
      "|      null|            Portugal|        16180|\n",
      "|      null|             Denmark|         8188|\n",
      "|      null|               Japan|        25218|\n",
      "|      null|               Spain|        26824|\n",
      "|      null|         Unspecified|         3300|\n",
      "|      null|           Singapore|         5234|\n",
      "|      null|             Bahrain|          260|\n",
      "|2010-12-01|                EIRE|          243|\n",
      "|2010-12-01|                null|        26814|\n",
      "|2010-12-01|              Norway|         1852|\n",
      "|2010-12-01|           Australia|          107|\n",
      "|2010-12-01|             Germany|          117|\n",
      "|2010-12-01|      United Kingdom|        23949|\n",
      "|2010-12-01|              France|          449|\n",
      "|2010-12-01|         Netherlands|           97|\n",
      "|2010-12-02|                EIRE|            4|\n",
      "|2010-12-02|                null|        21023|\n",
      "|2010-12-02|             Germany|          146|\n",
      "+----------+--------------------+-------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithDate.cube(\"date\", \"Country\").agg(sum(col(\"Quantity\")))\\\n",
    "    .select(\"Date\", \"Country\", \"sum(Quantity)\").orderBy(\"Date\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------------+--------------------+---------------------------------+------------------+\n",
      "|      date|Japan_sum(CAST(Quantity AS BIGINT))|Japan_sum(UnitPrice)|USA_sum(CAST(Quantity AS BIGINT))|USA_sum(UnitPrice)|\n",
      "+----------+-----------------------------------+--------------------+---------------------------------+------------------+\n",
      "|2011-03-07|                                  9|   95.22000000000001|                             null|              null|\n",
      "|2011-04-19|                               null|                null|                              137|              74.2|\n",
      "|2011-02-09|                               2962|              115.62|                             null|              null|\n",
      "|2011-10-12|                               null|                null|                            -1228|            217.93|\n",
      "|2011-11-29|                               2040|                1.79|                             null|              null|\n",
      "|2010-12-09|                               1488|                2.55|                             null|              null|\n",
      "|2011-09-14|                                144|                2.97|                             null|              null|\n",
      "|2011-12-06|                                -49|  19.679999999999996|                             null|              null|\n",
      "|2011-01-06|                                -45|                7.85|                             null|              null|\n",
      "|2011-10-21|                               null|                null|                              489|             64.71|\n",
      "|2011-12-05|                               null|                null|                              408|             42.71|\n",
      "|2011-04-04|                               -624|                2.55|                             null|              null|\n",
      "|2011-10-26|                               1124|               32.82|                             null|              null|\n",
      "|2011-05-13|                                743|  31.499999999999996|                             null|              null|\n",
      "|2011-11-17|                               2210|   97.44000000000003|                             null|              null|\n",
      "|2011-04-18|                               6432|                9.26|                             null|              null|\n",
      "|2011-07-24|                                120|                 2.9|                             null|              null|\n",
      "|2011-03-02|                                -11|  12.940000000000001|                             null|              null|\n",
      "|2011-12-02|                               null|                null|                              196|             13.75|\n",
      "|2010-12-12|                               2409|   91.96000000000001|                             null|              null|\n",
      "+----------+-----------------------------------+--------------------+---------------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted = dfWithDate.where(\"Country IN ('USA', 'Japan')\")\\\n",
    "    .select(\"date\", \"Country\", \"Quantity\", \"UnitPrice\")\\\n",
    "    .groupBy(\"date\").pivot(\"Country\").sum()\n",
    "pivoted.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
